{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the params.yaml file\n",
    "params = yaml.safe_load(open('params.yaml'))['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46914, 26), (46914,), (11729, 26), (11729,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the data and labels\n",
    "X = pd.read_csv(params['input_data_path']).values\n",
    "y = pd.read_csv(params['input_label_path']).values.ravel()\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 0.8879699889163611\n",
      "Random Forest Accuracy: 0.9523403529712678\n",
      "XGBoost Accuracy: 0.9530224230539688\n"
     ]
    }
   ],
   "source": [
    "# Creating a function to calculate accuracy\n",
    "def calc_accuracy(X_train, y_train, Model):\n",
    "\n",
    "    # Creating a model object\n",
    "    model = Model()\n",
    "\n",
    "    # Training the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the validation results\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Calculating the accuracy\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    # Returning the accuracy\n",
    "    return accuracy\n",
    "\n",
    "# Displaying the various accuracies\n",
    "print(f\"Multinomial Naive Bayes Accuracy: {calc_accuracy(X_train, y_train, MultinomialNB)}\")\n",
    "print(f\"Random Forest Accuracy: {calc_accuracy(X_train, y_train, RandomForestClassifier)}\")\n",
    "print(f\"XGBoost Accuracy: {calc_accuracy(X_train, y_train, XGBClassifier)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=None; total time=   1.9s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=None; total time=   1.9s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=None; total time=   1.9s\n",
      "[CV] END .learning_rate=None, max_depth=3, n_estimators=None; total time=   1.3s\n",
      "[CV] END .learning_rate=None, max_depth=3, n_estimators=None; total time=   1.3s\n",
      "[CV] END .learning_rate=None, max_depth=3, n_estimators=None; total time=   1.3s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=200; total time=   3.6s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=200; total time=   3.8s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=200; total time=   3.6s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=200; total time=   2.1s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=200; total time=   2.1s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=200; total time=   1.9s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=400; total time=   6.2s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=400; total time=   6.0s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=400; total time=   3.3s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=400; total time=   6.1s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=400; total time=   3.3s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=400; total time=   3.3s\n",
      "[CV] END .learning_rate=None, max_depth=4, n_estimators=None; total time=   1.3s\n",
      "[CV] END .learning_rate=None, max_depth=4, n_estimators=None; total time=   1.2s\n",
      "[CV] END .learning_rate=None, max_depth=4, n_estimators=None; total time=   1.3s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=500; total time=   7.5s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=500; total time=   7.4s\n",
      "[CV] END learning_rate=None, max_depth=None, n_estimators=500; total time=   7.4s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=500; total time=   4.1s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=500; total time=   4.2s\n",
      "[CV] END ..learning_rate=None, max_depth=4, n_estimators=200; total time=   2.1s\n",
      "[CV] END ..learning_rate=None, max_depth=3, n_estimators=500; total time=   4.2s\n",
      "[CV] END ..learning_rate=None, max_depth=4, n_estimators=200; total time=   2.4s\n",
      "[CV] END ..learning_rate=None, max_depth=4, n_estimators=200; total time=   2.1s\n",
      "[CV] END .learning_rate=None, max_depth=5, n_estimators=None; total time=   1.4s\n",
      "[CV] END .learning_rate=None, max_depth=5, n_estimators=None; total time=   1.3s\n",
      "[CV] END .learning_rate=None, max_depth=5, n_estimators=None; total time=   1.5s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END ..learning_rate=None, max_depth=4, n_estimators=400; total time=   4.7s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=200; total time=   3.3s[CV] END ..learning_rate=None, max_depth=4, n_estimators=400; total time=   4.8s\n",
      "\n",
      "[CV] END ..learning_rate=None, max_depth=4, n_estimators=400; total time=   4.9s\n",
      "[CV] END ..learning_rate=None, max_depth=4, n_estimators=500; total time=   6.0s\n",
      "[CV] END ..learning_rate=None, max_depth=4, n_estimators=500; total time=   6.0s\n",
      "[CV] END .learning_rate=None, max_depth=6, n_estimators=None; total time=   1.7s\n",
      "[CV] END .learning_rate=None, max_depth=6, n_estimators=None; total time=   1.7s\n",
      "[CV] END .learning_rate=None, max_depth=6, n_estimators=None; total time=   1.7s\n",
      "[CV] END ..learning_rate=None, max_depth=4, n_estimators=500; total time=   6.4s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=400; total time=   5.8s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=400; total time=   5.7s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=200; total time=   2.9s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=200; total time=   3.0s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=200; total time=   3.0s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=500; total time=   6.2s\n",
      "[CV] END ..learning_rate=None, max_depth=5, n_estimators=500; total time=   6.2s\n",
      "[CV] END .learning_rate=None, max_depth=7, n_estimators=None; total time=   1.8s\n",
      "[CV] END .learning_rate=None, max_depth=7, n_estimators=None; total time=   1.9s\n",
      "[CV] END .learning_rate=None, max_depth=7, n_estimators=None; total time=   1.9s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=400; total time=   5.6s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=400; total time=   5.7s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=400; total time=   5.6s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=200; total time=   3.2s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=200; total time=   3.1s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=200; total time=   3.1s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=500; total time=   6.6s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=500; total time=   6.7s\n",
      "[CV] END ..learning_rate=None, max_depth=6, n_estimators=500; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=None; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=None; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=None; total time=   1.5s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=200; total time=   2.8s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=400; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=200; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=200; total time=   2.8s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=400; total time=   6.0s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=400; total time=   6.0s\n",
      "[CV] END ..learning_rate=0.1, max_depth=3, n_estimators=None; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.1, max_depth=3, n_estimators=None; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.1, max_depth=3, n_estimators=None; total time=   1.1s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=500; total time=   7.5s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=500; total time=   7.5s\n",
      "[CV] END ..learning_rate=None, max_depth=7, n_estimators=500; total time=   7.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   1.7s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=400; total time=   5.2s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=400; total time=   5.4s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=400; total time=   5.3s\n",
      "[CV] END ..learning_rate=0.1, max_depth=4, n_estimators=None; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.1, max_depth=4, n_estimators=None; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.1, max_depth=4, n_estimators=None; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=400; total time=   3.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=400; total time=   3.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=400; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=500; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=500; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=None, n_estimators=500; total time=   6.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   1.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   1.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   1.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   3.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   3.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   3.7s\n",
      "[CV] END ..learning_rate=0.1, max_depth=5, n_estimators=None; total time=   1.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=5, n_estimators=None; total time=   1.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=5, n_estimators=None; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=400; total time=   3.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=400; total time=   3.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=400; total time=   3.8s\n",
      "[CV] END ..learning_rate=0.1, max_depth=6, n_estimators=None; total time=   1.5s\n",
      "[CV] END ..learning_rate=0.1, max_depth=6, n_estimators=None; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..learning_rate=0.1, max_depth=6, n_estimators=None; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=500; total time=   4.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=500; total time=   4.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   4.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   4.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   4.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   5.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   5.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   5.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=7, n_estimators=None; total time=   1.7s\n",
      "[CV] END ..learning_rate=0.1, max_depth=7, n_estimators=None; total time=   1.7s\n",
      "[CV] END ..learning_rate=0.1, max_depth=7, n_estimators=None; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=400; total time=   5.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=400; total time=   5.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=400; total time=   5.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   3.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   3.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   3.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=500; total time=   6.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=500; total time=   6.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=500; total time=   6.3s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=None; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=None; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=None; total time=   1.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   6.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   6.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=200; total time=   3.1s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=200; total time=   3.1s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=200; total time=   3.2s\n",
      "[CV] END .learning_rate=0.01, max_depth=3, n_estimators=None; total time=   1.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=3, n_estimators=None; total time=   1.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=3, n_estimators=None; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   7.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   7.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   7.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   1.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   1.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=400; total time=   5.9s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=400; total time=   5.9s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=400; total time=   6.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=4, n_estimators=None; total time=   1.1s\n",
      "[CV] END .learning_rate=0.01, max_depth=4, n_estimators=None; total time=   1.1s\n",
      "[CV] END .learning_rate=0.01, max_depth=4, n_estimators=None; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=400; total time=   3.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=400; total time=   3.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=400; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=500; total time=   7.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=500; total time=   6.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   1.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   3.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   3.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   3.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, max_depth=None, n_estimators=500; total time=   7.1s\n",
      "[CV] END .learning_rate=0.01, max_depth=5, n_estimators=None; total time=   1.4s\n",
      "[CV] END .learning_rate=0.01, max_depth=5, n_estimators=None; total time=   1.3s\n",
      "[CV] END .learning_rate=0.01, max_depth=5, n_estimators=None; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=400; total time=   4.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=400; total time=   4.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=400; total time=   3.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END .learning_rate=0.01, max_depth=6, n_estimators=None; total time=   1.6s\n",
      "[CV] END .learning_rate=0.01, max_depth=6, n_estimators=None; total time=   1.6s\n",
      "[CV] END .learning_rate=0.01, max_depth=6, n_estimators=None; total time=   1.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=500; total time=   5.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=500; total time=   5.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=500; total time=   5.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=400; total time=   5.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=400; total time=   5.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=400; total time=   5.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   3.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   3.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   3.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=   6.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=   6.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=   6.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=7, n_estimators=None; total time=   1.8s\n",
      "[CV] END .learning_rate=0.01, max_depth=7, n_estimators=None; total time=   1.8s\n",
      "[CV] END .learning_rate=0.01, max_depth=7, n_estimators=None; total time=   1.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=400; total time=   5.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=400; total time=   5.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=400; total time=   6.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   3.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   4.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   3.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=500; total time=   7.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=500; total time=   7.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=500; total time=   7.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=400; total time=   6.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=400; total time=   6.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=400; total time=   6.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=   5.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=   5.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=   5.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9529371642936312"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the parameters for the classifier\n",
    "xgb_params = {\n",
    "    'learning_rate' : [None, 0.1, 0.01],\n",
    "    'n_estimators' : [None, 200, 400, 500],\n",
    "    'max_depth' : [None, 3, 4, 5, 6, 7]\n",
    "}\n",
    "\n",
    "# Creating an xgboost object\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Performing hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=xgb_params, n_jobs=-1, cv=3, verbose=2)\n",
    "\n",
    "# Fitting the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Performing predictions on the validation data\n",
    "y_pred = grid_search.predict(X_val)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run sassy-goat-552 at: https://dagshub.com/siddmirjank2696/Loan-Approval-Prediction-AWS-Deployment.mlflow/#/experiments/0/runs/29066c6f20f74adaa46dde3e5c5648ae\n",
      "üß™ View experiment at: https://dagshub.com/siddmirjank2696/Loan-Approval-Prediction-AWS-Deployment.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Setting mlflow configuration with dagshub\n",
    "os.environ['MLFLOW_TRACKING_URI']=\"https://dagshub.com/siddmirjank2696/Diabetes-Detection-MLflow.mlflow\"\n",
    "os.environ['MLFLOW_TRACKING_USERNAME']=\"siddmirjank2696\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"ed2891a2b1abb4d15f5d9a6a45f8bb11829b6bed\"\n",
    "\n",
    "# Setting the mlflow tracking uri\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/siddmirjank2696/Loan-Approval-Prediction-AWS-Deployment.mlflow\")\n",
    "\n",
    "# Setting the experiment name\n",
    "mlflow.set_experiment(\"XgBoost Tracking\")\n",
    "\n",
    "# Starting an mlflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Creating an xgboost object\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    # Fititng the data to the model\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Performing predictions on the validation data\n",
    "    y_pred = xgb.predict(X_val)\n",
    "\n",
    "    # Calculating the accuracy\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    # Logging the accuracy\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test data\n",
    "person_test_data = pd.read_csv(params['person_data_path'])\n",
    "loan_test_data = pd.read_csv(params['loan_data_path'])\n",
    "\n",
    "# Merging the test data to form one csv file\n",
    "predictions = pd.merge(person_test_data, loan_test_data, how=\"inner\", on=\"id\")\n",
    "\n",
    "# Dropping id from the test data because it does not contribute to the prediction\n",
    "test_data = predictions.drop(\"id\", axis=1)\n",
    "\n",
    "# Loading the transformer\n",
    "transformer = pickle.load(open(params['transformer_path'], 'rb'))\n",
    "\n",
    "# Transforming the test data into the same format as the train data\n",
    "X_test = transformer.transform(test_data)\n",
    "\n",
    "# Predicting the loan status on the test data\n",
    "y_test = xgb.predict(X_test)\n",
    "\n",
    "# Adding the predictions to the csv file\n",
    "predictions[\"loan_status\"] = y_test\n",
    "\n",
    "# Creating a directory to save the predictions and the model\n",
    "os.makedirs(\"data/predictions\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Saving the predictions as a csv file\n",
    "predictions.to_csv(params['output_path'], index=False)\n",
    "\n",
    "# Saving the model as a pickle file\n",
    "pickle.dump(xgb, open(params['model_path'], 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run tasteful-zebra-211 at: https://dagshub.com/siddmirjank2696/Loan-Approval-Prediction-AWS-Deployment.mlflow/#/experiments/0/runs/b6ebce83a615464a8a0a1e1c1d34544f\n",
      "üß™ View experiment at: https://dagshub.com/siddmirjank2696/Loan-Approval-Prediction-AWS-Deployment.mlflow/#/experiments/0\n",
      "\n",
      "The model and predictions were saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Accessing the params.yaml file\n",
    "params = yaml.safe_load(open('params.yaml'))['train']\n",
    "\n",
    "# Creating a function to train the data\n",
    "def train_data(input_data_path, input_label_path, person_test_data_path, loan_test_data_path, transformer_path, output_path, model_path):\n",
    "\n",
    "    # Importing the data and labels\n",
    "    X = pd.read_csv(input_data_path).values\n",
    "    y = pd.read_csv(input_label_path).values.ravel()\n",
    "\n",
    "    # Splitting the data into train and test\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Setting mlflow configuration with dagshub\n",
    "    os.environ['MLFLOW_TRACKING_URI']=\"https://dagshub.com/siddmirjank2696/Diabetes-Detection-MLflow.mlflow\"\n",
    "    os.environ['MLFLOW_TRACKING_USERNAME']=\"siddmirjank2696\"\n",
    "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"ed2891a2b1abb4d15f5d9a6a45f8bb11829b6bed\"\n",
    "\n",
    "    # Setting the mlflow tracking uri\n",
    "    mlflow.set_tracking_uri(\"https://dagshub.com/siddmirjank2696/Loan-Approval-Prediction-AWS-Deployment.mlflow\")\n",
    "\n",
    "    # Setting the experiment name\n",
    "    mlflow.set_experiment(\"XgBoost Tracking\")\n",
    "\n",
    "    # Starting an mlflow run\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        # Creating an xgboost object\n",
    "        xgb = XGBClassifier()\n",
    "\n",
    "        # Fititng the data to the model\n",
    "        xgb.fit(X_train, y_train)\n",
    "\n",
    "        # Performing predictions on the validation data\n",
    "        y_pred = xgb.predict(X_val)\n",
    "\n",
    "        # Calculating the accuracy\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "        # Logging the accuracy\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Loading the test data\n",
    "    person_test_data = pd.read_csv(person_test_data_path)\n",
    "    loan_test_data = pd.read_csv(loan_test_data_path)\n",
    "\n",
    "    # Merging the test data to form one csv file\n",
    "    predictions = pd.merge(person_test_data, loan_test_data, how=\"inner\", on=\"id\")\n",
    "\n",
    "    # Dropping id from the test data because it does not contribute to the prediction\n",
    "    test_data = predictions.drop(\"id\", axis=1)\n",
    "\n",
    "    # Loading the transformer\n",
    "    transformer = pickle.load(open(transformer_path, 'rb'))\n",
    "\n",
    "    # Transforming the test data into the same format as the train data\n",
    "    X_test = transformer.transform(test_data)\n",
    "\n",
    "    # Predicting the loan status on the test data\n",
    "    y_test = xgb.predict(X_test)\n",
    "\n",
    "    # Adding the predictions to the csv file\n",
    "    predictions[\"loan_status\"] = y_test\n",
    "\n",
    "    # Creating a directory to save the predictions and the model\n",
    "    os.makedirs(\"data/predictions\", exist_ok=True)\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    # Saving the predictions as a csv file\n",
    "    predictions.to_csv(output_path, index=False)\n",
    "\n",
    "    # Saving the model as a pickle file\n",
    "    pickle.dump(xgb, open(model_path, 'wb'))\n",
    "\n",
    "    # Displaying the success message\n",
    "    print(\"\\nThe model and predictions were saved successfully!\")\n",
    "\n",
    "    # Returning nothing\n",
    "    return\n",
    "\n",
    "# Calling the function to train the model\n",
    "train_data(params['input_data_path'], params['input_label_path'], params['person_data_path'], params['loan_data_path'], \n",
    "           params['transformer_path'], params['output_path'], params['model_path'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
